{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cybersecurity-excellence-awards.com/wp-content/uploads/2017/06/366812.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1><center>Darwin Unsupervised Model Building </center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior to getting started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, if you have just received a new api key from support, you will need to register your key and create a new user (see Register user)\n",
    "\n",
    "Second, in the Environment Variables cell: \n",
    "1. Set your username and password to ensure that you're able to log in successfully\n",
    "2. Set the path to the location of your datasets if you are using your own data.  The path is set for the examples.\n",
    "  <br><b>NOTE:</b> We provide two ways to analyze feature importance. One is to use the entire dataset; the other one is to analyze a few samples to understand individual samples. In the latter case, we advise users to use a small dataset (<=500) because it takes long time to process individual samples. \n",
    "\n",
    "Here are a few things to be mindful of:\n",
    "1. For every run, check the job status (i.e. requested, failed, running, completed) and wait for job to complete before proceeding. \n",
    "2. If you're not satisfied with your model and think that Darwin can benefit from extra training, use the resume function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Darwin SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'https://amb-demo-api.sparkcognition.com/v1/')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from amb_sdk.sdk import DarwinSdk\n",
    "ds = DarwinSdk()\n",
    "ds.set_url('https://amb-demo-api.sparkcognition.com/v1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register user (if needed, read above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401: UNAUTHORIZED - {\"message\": \"Incorrect username or password\"}\n",
      "\n",
      "401: UNAUTHORIZED - {\"msg\":\"Missing Authorization Header\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use only if you have a new api-key and \n",
    "# no registered users - fill in the appropriate fields then execute\n",
    "\n",
    "#Enter your support provided api key and api key password below to register/create new users\n",
    "api_key = ''\n",
    "api_key_pw = ''\n",
    "status, msg = ds.auth_login(api_key_pw, api_key)\n",
    "if not status:\n",
    "    print(msg)\n",
    "\n",
    "#Create a new user\n",
    "status, msg = ds.auth_register_user('username', 'password','email@emailaddress.com')\n",
    "if not status:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set your user id and password accordingly\n",
    "USER='idunlap@rocketmail.com'\n",
    "PW='5uVGHsTHrQ'\n",
    "\n",
    "# Set path to datasets - The default below assumes Jupyter was started from amb-sdk/examples/Enterprise/\n",
    "# Modify accordingly if you wish to use your own data\n",
    "PATH_TO_DATASET = '../../sets/'\n",
    "TRAIN_DATASET = 'pulsars.csv'\n",
    "PREDICT_DATASET = 'pulsars_predict.csv'\n",
    "\n",
    "# A timestamp is used to create a unique name in the event you execute the workflow multiple times or with \n",
    "# different datasets.  File names must be unique in Darwin.\n",
    "import datetime\n",
    "ts = '{:%Y%m%d%H%M%S}'.format(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are logged in.\n"
     ]
    }
   ],
   "source": [
    "status, msg = ds.auth_login_user(USER,PW)\n",
    "if not status:\n",
    "    print(msg)\n",
    "else:\n",
    "    print('You are logged in.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read dataset and view a file snippet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_profile</th>\n",
       "      <th>std_profile</th>\n",
       "      <th>kurt_profile</th>\n",
       "      <th>skew_profile</th>\n",
       "      <th>mean_dmsnr</th>\n",
       "      <th>std_dmsnr</th>\n",
       "      <th>kurt_dmsnr</th>\n",
       "      <th>skew_dmsnr</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111.093750</td>\n",
       "      <td>47.341089</td>\n",
       "      <td>0.435469</td>\n",
       "      <td>0.471339</td>\n",
       "      <td>2.386288</td>\n",
       "      <td>15.867173</td>\n",
       "      <td>9.327098</td>\n",
       "      <td>103.545876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>49.203341</td>\n",
       "      <td>0.563215</td>\n",
       "      <td>0.382150</td>\n",
       "      <td>1.601171</td>\n",
       "      <td>14.657767</td>\n",
       "      <td>11.381829</td>\n",
       "      <td>148.334350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115.304688</td>\n",
       "      <td>43.653207</td>\n",
       "      <td>0.448319</td>\n",
       "      <td>0.614359</td>\n",
       "      <td>3.158027</td>\n",
       "      <td>21.378754</td>\n",
       "      <td>8.347430</td>\n",
       "      <td>76.310271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108.554688</td>\n",
       "      <td>52.559016</td>\n",
       "      <td>0.138068</td>\n",
       "      <td>-0.442340</td>\n",
       "      <td>1.787625</td>\n",
       "      <td>12.108555</td>\n",
       "      <td>11.262459</td>\n",
       "      <td>180.074252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136.429688</td>\n",
       "      <td>49.552164</td>\n",
       "      <td>-0.180418</td>\n",
       "      <td>0.370338</td>\n",
       "      <td>9.066054</td>\n",
       "      <td>37.284742</td>\n",
       "      <td>4.270014</td>\n",
       "      <td>17.700441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_profile  std_profile  kurt_profile  skew_profile  mean_dmsnr  \\\n",
       "0    111.093750    47.341089      0.435469      0.471339    2.386288   \n",
       "1    105.000000    49.203341      0.563215      0.382150    1.601171   \n",
       "2    115.304688    43.653207      0.448319      0.614359    3.158027   \n",
       "3    108.554688    52.559016      0.138068     -0.442340    1.787625   \n",
       "4    136.429688    49.552164     -0.180418      0.370338    9.066054   \n",
       "\n",
       "   std_dmsnr  kurt_dmsnr  skew_dmsnr  class  \n",
       "0  15.867173    9.327098  103.545876      0  \n",
       "1  14.657767   11.381829  148.334350      0  \n",
       "2  21.378754    8.347430   76.310271      0  \n",
       "3  12.108555   11.262459  180.074252      0  \n",
       "4  37.284742    4.270014   17.700441      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataset\n",
    "df = pd.read_csv(os.path.join(PATH_TO_DATASET, TRAIN_DATASET))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload dataset to Darwin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{'dataset_name': 'pulsars.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset\n",
    "status, dataset = ds.upload_dataset(os.path.join(PATH_TO_DATASET, TRAIN_DATASET))\n",
    "print(status)\n",
    "print(dataset)\n",
    "\n",
    "if not status:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data\n",
    "Before creating a model, users need to analyze data and clean data first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Requested', 'starttime': '2019-04-17T21:59:36.469952', 'endtime': None, 'percent_complete': 0, 'job_type': 'AnalyzeData', 'loss': None, 'generations': None, 'dataset_names': ['pulsars.csv'], 'artifact_names': ['Darwin_analyze_data_artifact-20190417215937'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T21:59:36.469952', 'endtime': None, 'percent_complete': 0, 'job_type': 'AnalyzeData', 'loss': None, 'generations': None, 'dataset_names': ['pulsars.csv'], 'artifact_names': ['Darwin_analyze_data_artifact-20190417215937'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T21:59:36.469952', 'endtime': None, 'percent_complete': 10, 'job_type': 'AnalyzeData', 'loss': None, 'generations': None, 'dataset_names': ['pulsars.csv'], 'artifact_names': ['Darwin_analyze_data_artifact-20190417215937'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T21:59:36.469952', 'endtime': None, 'percent_complete': 10, 'job_type': 'AnalyzeData', 'loss': None, 'generations': None, 'dataset_names': ['pulsars.csv'], 'artifact_names': ['Darwin_analyze_data_artifact-20190417215937'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T21:59:36.469952', 'endtime': '2019-04-17T22:00:24.514', 'percent_complete': 100, 'job_type': 'AnalyzeData', 'loss': None, 'generations': None, 'dataset_names': ['pulsars.csv'], 'artifact_names': ['Darwin_analyze_data_artifact-20190417215937'], 'model_name': None, 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "status, analyze_id = ds.analyze_data(TRAIN_DATASET, \n",
    "                                     job_name = 'Darwin_analyze_data_job' + \"-\" + ts, \n",
    "                                     artifact_name = 'Darwin_analyze_data_artifact' + \"-\" + ts)\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job('Darwin_analyze_data_job' + \"-\" + ts)\n",
    "else:\n",
    "    print(analyze_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'status': 'Complete',\n",
       "  'starttime': '2019-04-17T21:59:36.469952',\n",
       "  'endtime': '2019-04-17T22:00:24.514',\n",
       "  'percent_complete': 100,\n",
       "  'job_type': 'AnalyzeData',\n",
       "  'loss': None,\n",
       "  'generations': None,\n",
       "  'dataset_names': ['pulsars.csv'],\n",
       "  'artifact_names': ['Darwin_analyze_data_artifact-20190417215937'],\n",
       "  'model_name': None,\n",
       "  'job_error': ''})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.lookup_job_status_name(analyze_id['job_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "\n",
    "Starting Version 1.6, Darwin SDK offers a way to clean your data outside of model training. Every dataset needs to be cleaned before creating a model. There is no need to save the cleaned data and upload it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully cleaned!\n"
     ]
    }
   ],
   "source": [
    "# Clean dataset\n",
    "status, job_id = ds.clean_data(dataset_name=TRAIN_DATASET)\n",
    "if not status:\n",
    "    print(job_id)\n",
    "else:\n",
    "    print('Data has been successfully cleaned!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build unsupervised models, which cluster data and perform anomaly detection, Darwin goes through the following steps:\n",
    "1. Determines an approximate number of clusters to start with using a single pass with a hierarchical method\n",
    "2. Iterates on subsets of the data using a Spectral-Net algorithm to determine the ideal number of clusters\n",
    "3. Proceeds to cluster the data using a Spectral-Net approach\n",
    "\n",
    "In the cell below, specify the parameters used to create the model:\n",
    "- model: the name of your model\n",
    "- max_epochs: the number of epochs to train the model, one epoch indicates one scan of the entire dataset\n",
    "- n_clusters: the number of clusters, either an integer or 'auto', if left with 'auto', the unsupervised algorithm will compute a number for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'starttime': '2019-04-17T22:00:40.617364', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': None, 'model_name': 'model-20190417215937', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T22:00:40.617364', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': None, 'model_name': 'model-20190417215937', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T22:00:40.617364', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': None, 'model_name': 'model-20190417215937', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T22:00:40.617364', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': None, 'model_name': 'model-20190417215937', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T22:00:40.617364', 'endtime': '2019-04-17T22:01:39.942014', 'percent_complete': 100, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': None, 'model_name': 'model-20190417215937', 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = \"model\" + \"-\" + ts\n",
    "max_epochs = 20\n",
    "n_clusters = 2\n",
    "status, job_id = ds.create_model(dataset_names=TRAIN_DATASET,\n",
    "                                 model_name=model,\n",
    "                                 max_epochs=max_epochs,\n",
    "                                 n_clusters=n_clusters)\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'status': 'Complete',\n",
       "  'starttime': '2019-04-17T22:00:40.617364',\n",
       "  'endtime': '2019-04-17T22:01:39.942014',\n",
       "  'percent_complete': 100,\n",
       "  'job_type': 'TrainModel',\n",
       "  'loss': None,\n",
       "  'generations': 0,\n",
       "  'dataset_names': ['pulsars.csv'],\n",
       "  'artifact_names': None,\n",
       "  'model_name': 'model-20190417215937',\n",
       "  'job_error': ''})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up job status\n",
    "ds.lookup_job_status_name(job_id['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'type': 'Unsupervised',\n",
       "  'updated_at': '2019-04-17T22:01:39.935142',\n",
       "  'trained_on': ['pulsars.csv'],\n",
       "  'loss': None,\n",
       "  'generations': 0,\n",
       "  'parameters': {'n_clusters': 2,\n",
       "   'max_generation': 20,\n",
       "   'train_time': '00:10',\n",
       "   'recurrent': None,\n",
       "   'max_unique_values': 50,\n",
       "   'max_int_uniques': 15,\n",
       "   'impute': 'mean',\n",
       "   'big_data': False},\n",
       "  'description': {'model': \"UnsupervisedPipeline(anomaly=False, anomaly_prior=0.0015, auto_save_per=10,\\n           clustering=True, clustermethod='GaussianMixture',\\n           job_id='26374df0-6186-11e9-9ed5-6fd12eab83cc',\\n           max_generation=20, max_time=600,\\n           model_file='models/8f7f1eea-4fc6-11e9-ba76-eb31f920f59e_model-20190417215937',\\n           n_clusters=2, preproc_anomaly=None, recurrent=None, verbose=2)\",\n",
       "   'genome_type': 'Unsupervised'},\n",
       "  'train_time_seconds': 59,\n",
       "  'algorithm': None,\n",
       "  'running_job_id': None})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the model\n",
    "ds.lookup_model_name(job_id['model_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Training (Optional)\n",
    "Run the following cell for extra training, no need to specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'starttime': '2019-04-17T22:01:43.108881', 'endtime': None, 'percent_complete': 0, 'job_type': 'UpdateModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': None, 'model_name': 'model-20190417215937', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T22:01:43.108881', 'endtime': '2019-04-17T22:01:56.967556', 'percent_complete': 100, 'job_type': 'UpdateModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': None, 'model_name': 'model-20190417215937', 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "# Train some more\n",
    "extra_epochs = 10\n",
    "status, job_id = ds.resume_training_model(dataset_names=TRAIN_DATASET,\n",
    "                                          model_name=model,\n",
    "                                          max_epochs=extra_epochs,\n",
    "                                          n_clusters=n_clusters)\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Run the following cell for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'starttime': '2019-04-17T22:02:00.347664', 'endtime': None, 'percent_complete': 0, 'job_type': 'RunModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': ['1fa52d74159b42718572a39918a2978d'], 'model_name': 'model-20190417215937', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T22:02:00.347664', 'endtime': '2019-04-17T22:02:03.003864', 'percent_complete': 100, 'job_type': 'RunModel', 'loss': None, 'generations': 0, 'dataset_names': ['pulsars.csv'], 'artifact_names': ['1fa52d74159b42718572a39918a2978d'], 'model_name': 'model-20190417215937', 'job_error': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'Job completed')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "status, artifact = ds.run_model(TRAIN_DATASET, \n",
    "                                model, \n",
    "                                supervised=False)\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "status, pred_file = ds.download_artifact(artifact['artifact_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12.691042</td>\n",
       "      <td>[0.9666828207784542, 0.033317179221545666]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-12.691042</td>\n",
       "      <td>[0.9619552834389405, 0.03804471656105941]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.691042</td>\n",
       "      <td>[0.9583237944289412, 0.041676205571058604]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12.691042</td>\n",
       "      <td>[0.9563806361669092, 0.04361936383309067]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.691042</td>\n",
       "      <td>[0.9259344943050699, 0.07406550569493016]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anomaly_score                               predict_proba  prediction\n",
       "0     -12.691042  [0.9666828207784542, 0.033317179221545666]           0\n",
       "1     -12.691042   [0.9619552834389405, 0.03804471656105941]           0\n",
       "2     -12.691042  [0.9583237944289412, 0.041676205571058604]           0\n",
       "3     -12.691042   [0.9563806361669092, 0.04361936383309067]           0\n",
       "4     -12.691042   [0.9259344943050699, 0.07406550569493016]           0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View prediction\n",
    "df = pd.read_csv(pred_file['filename'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Model\n",
    "Analyze model provides feature importance ranked by the model. It indicates a general view of which features pose a bigger impact on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'starttime': '2019-04-17T22:02:18.027824', 'endtime': None, 'percent_complete': 0, 'job_type': 'AnalyzeModel', 'loss': None, 'generations': 0, 'dataset_names': None, 'artifact_names': ['Darwin_analyze_model_artifact-20190417215937'], 'model_name': 'model-20190417215937', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T22:02:18.027824', 'endtime': '2019-04-17T22:02:21.042838', 'percent_complete': 100, 'job_type': 'AnalyzeModel', 'loss': None, 'generations': 0, 'dataset_names': None, 'artifact_names': ['Darwin_analyze_model_artifact-20190417215937'], 'model_name': 'model-20190417215937', 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "status, analyze_id = ds.analyze_model(job_id['model_name'], \n",
    "                                      job_name='Darwin_analyze_model_job-' + ts, \n",
    "                                      artifact_name='Darwin_analyze_model_artifact-' + ts)\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job('Darwin_analyze_model_job-' + ts)\n",
    "else:\n",
    "    print(analyze_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'status': 'Complete',\n",
       "  'starttime': '2019-04-17T22:02:18.027824',\n",
       "  'endtime': '2019-04-17T22:02:21.042838',\n",
       "  'percent_complete': 100,\n",
       "  'job_type': 'AnalyzeModel',\n",
       "  'loss': None,\n",
       "  'generations': 0,\n",
       "  'dataset_names': None,\n",
       "  'artifact_names': ['Darwin_analyze_model_artifact-20190417215937'],\n",
       "  'model_name': 'model-20190417215937',\n",
       "  'job_error': ''})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.lookup_job_status_name('Darwin_analyze_model_job-' + ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloade and print the top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skew_profile    0.196476\n",
       "kurt_profile    0.141127\n",
       "skew_dmsnr      0.133543\n",
       "std_profile     0.120845\n",
       "kurt_dmsnr      0.096207\n",
       "mean_profile    0.085166\n",
       "mean_dmsnr      0.084242\n",
       "std_dmsnr       0.071762\n",
       "class = 1       0.070633\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status, feature_importance = ds.download_artifact('Darwin_analyze_model_artifact-' + ts)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Prediction\n",
    "Different from Analyze Model, the Analyze Prediction provides a way to analyze feature importance for each data point. The output estimates how each feature added or subtracted from a known base-value to result in the overall prediction that was made.  <br>\n",
    "**You need to set the path to the dataset which contains all the samples you want to analyze (max rows = 500)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data that you are interested in feature importance (max: 500 rows)\n",
    "status, dataset = ds.upload_dataset(os.path.join(PATH_TO_DATASET, PREDICT_DATASET))\n",
    "if not status:\n",
    "    print(dataset)\n",
    "    \n",
    "if status:\n",
    "    dataset_by_row=dataset['dataset_name']\n",
    "else:\n",
    "    print(\"Upload data failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'starttime': '2019-04-17T22:02:35.761435', 'endtime': None, 'percent_complete': 0, 'job_type': 'AnalyzePredictions', 'loss': None, 'generations': 0, 'dataset_names': None, 'artifact_names': ['Analyze_prediction_artifact-20190417215937'], 'model_name': 'model-20190417215937', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T22:02:35.761435', 'endtime': '2019-04-17T22:02:40.70888', 'percent_complete': 100, 'job_type': 'AnalyzePredictions', 'loss': None, 'generations': 0, 'dataset_names': None, 'artifact_names': ['Analyze_prediction_artifact-20190417215937'], 'model_name': 'model-20190417215937', 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "status, analyze_id = ds.analyze_predictions(job_id['model_name'], \n",
    "                                            PREDICT_DATASET, \n",
    "                                            job_name='Analyze_prediction_job-' + ts, \n",
    "                                            artifact_name='Analyze_prediction_artifact-' + ts)\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job('Analyze_prediction_job-' + ts)\n",
    "else:\n",
    "    print(analyze_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'status': 'Complete',\n",
       "  'starttime': '2019-04-17T22:02:35.761435',\n",
       "  'endtime': '2019-04-17T22:02:40.70888',\n",
       "  'percent_complete': 100,\n",
       "  'job_type': 'AnalyzePredictions',\n",
       "  'loss': None,\n",
       "  'generations': 0,\n",
       "  'dataset_names': None,\n",
       "  'artifact_names': ['Analyze_prediction_artifact-20190417215937'],\n",
       "  'model_name': 'model-20190417215937',\n",
       "  'job_error': ''})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.lookup_job_status_name('Analyze_prediction_job-' + ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and print the top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_profile_shap</th>\n",
       "      <th>std_profile_shap</th>\n",
       "      <th>kurt_profile_shap</th>\n",
       "      <th>skew_profile_shap</th>\n",
       "      <th>mean_dmsnr_shap</th>\n",
       "      <th>std_dmsnr_shap</th>\n",
       "      <th>kurt_dmsnr_shap</th>\n",
       "      <th>skew_dmsnr_shap</th>\n",
       "      <th>class = 1_shap</th>\n",
       "      <th>base_value</th>\n",
       "      <th>predicted_proba</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057928</td>\n",
       "      <td>0.081586</td>\n",
       "      <td>0.061330</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.084346</td>\n",
       "      <td>0.082562</td>\n",
       "      <td>0.022604</td>\n",
       "      <td>0.443911</td>\n",
       "      <td>0.902422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068686</td>\n",
       "      <td>0.086406</td>\n",
       "      <td>0.071951</td>\n",
       "      <td>0.070056</td>\n",
       "      <td>0.027363</td>\n",
       "      <td>0.039938</td>\n",
       "      <td>0.063032</td>\n",
       "      <td>0.062591</td>\n",
       "      <td>0.030716</td>\n",
       "      <td>0.443911</td>\n",
       "      <td>0.950183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060826</td>\n",
       "      <td>0.093792</td>\n",
       "      <td>0.063636</td>\n",
       "      <td>0.062760</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>0.040270</td>\n",
       "      <td>0.077618</td>\n",
       "      <td>0.078794</td>\n",
       "      <td>0.020414</td>\n",
       "      <td>0.443911</td>\n",
       "      <td>0.589138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.067299</td>\n",
       "      <td>0.091110</td>\n",
       "      <td>0.068313</td>\n",
       "      <td>0.068326</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>0.063223</td>\n",
       "      <td>0.047388</td>\n",
       "      <td>0.037772</td>\n",
       "      <td>0.443911</td>\n",
       "      <td>0.963259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.022155</td>\n",
       "      <td>-0.078355</td>\n",
       "      <td>-0.048350</td>\n",
       "      <td>-0.071799</td>\n",
       "      <td>-0.067388</td>\n",
       "      <td>-0.046311</td>\n",
       "      <td>-0.064381</td>\n",
       "      <td>-0.057761</td>\n",
       "      <td>-0.061093</td>\n",
       "      <td>0.556089</td>\n",
       "      <td>0.993726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_profile_shap  std_profile_shap  kurt_profile_shap  skew_profile_shap  \\\n",
       "0           0.057928          0.081586           0.061330           0.060390   \n",
       "1           0.068686          0.086406           0.071951           0.070056   \n",
       "2           0.060826          0.093792           0.063636           0.062760   \n",
       "3           0.067299          0.091110           0.068313           0.068326   \n",
       "4          -0.022155         -0.078355          -0.048350          -0.071799   \n",
       "\n",
       "   mean_dmsnr_shap  std_dmsnr_shap  kurt_dmsnr_shap  skew_dmsnr_shap  \\\n",
       "0         0.025644        0.044100         0.084346         0.082562   \n",
       "1         0.027363        0.039938         0.063032         0.062591   \n",
       "2         0.022066        0.040270         0.077618         0.078794   \n",
       "3         0.034789        0.042636         0.063223         0.047388   \n",
       "4        -0.067388       -0.046311        -0.064381        -0.057761   \n",
       "\n",
       "   class = 1_shap  base_value  predicted_proba  predicted_class  \n",
       "0        0.022604    0.443911         0.902422                0  \n",
       "1        0.030716    0.443911         0.950183                0  \n",
       "2        0.020414    0.443911         0.589138                0  \n",
       "3        0.037772    0.443911         0.963259                0  \n",
       "4       -0.061093    0.556089         0.993726                1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status, feature_importance = ds.download_artifact('Analyze_prediction_artifact-' + ts)\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
